import pdfplumber
import re
import os
from datetime import datetime, timedelta
from dateutil.parser import parse  # å…¼å®¹ä¸­æ–‡æ—¥æœŸè§£æ

# -------------------------- å…¨å±€é…ç½®é¡¹ --------------------------
# æ›¿æ¢ä¸ºä½ çš„ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„
TARGET_DIR = r'E:\System\download\å‚å•†ROHSã€REACH - å‰¯æœ¬\4-ä¸€è¯º'
# ä»…ä¿ç•™ä¸­æ–‡æ ‡æ³¨çš„åŒ¹é…è§„åˆ™ï¼ˆå®Œå…¨å¿½ç•¥è‹±æ–‡ï¼‰
target_keys = {
    "å®¢æˆ·åç§°": [
        # ä»…åŒ¹é…ã€ŒæŠ¥å‘ŠæŠ¬å¤´å…¬å¸åç§°ã€ä¸­æ–‡æ ‡æ³¨ï¼Œå…¼å®¹å†’å·/ç©ºæ ¼/æ¢è¡Œ
        r"æŠ¥å‘ŠæŠ¬å¤´å…¬å¸åç§°\s*[:ï¼š]\s*([^\n]+)",
        r"æŠ¥å‘ŠæŠ¬å¤´å…¬å¸åç§°\s*\n\s*([^\n]+)"
    ],
    "æ ·å“åç§°": [
        # ä»…åŒ¹é…ã€Œæ ·å“åç§°ã€ä¸­æ–‡æ ‡æ³¨ï¼Œå…¼å®¹å†’å·/ç©ºæ ¼/æ¢è¡Œ
        r"æ ·å“åç§°\s*[:ï¼š]\s*([^\n]+)",
        r"æ ·å“åç§°\s*\n\s*([^\n]+)"
    ],
    "æ ·å“æ¥æ”¶æ—¶é—´": [
        # ä»…åŒ¹é…ã€Œæ ·å“æ¥æ”¶æ—¥æœŸã€ä¸­æ–‡æ ‡æ³¨ï¼Œå…¼å®¹å†’å·/ç©ºæ ¼/æ¢è¡Œ
        r"æ ·å“æ¥æ”¶æ—¥æœŸ\s*[:ï¼š]\s*([^\n]+)",
        r"æ ·å“æ¥æ”¶æ—¥æœŸ\s*\n\s*([^\n]+)"
    ]
}
# æŠ¥å‘Šæœ‰æ•ˆæœŸï¼ˆå¤©ï¼‰
expire_days = 365
# æ£€æµ‹ç±»å‹å…³é”®è¯ï¼ˆROHS/REACHç­‰ï¼ŒæŒ‰éœ€è°ƒæ•´ï¼‰
target_keywords = ["rohs", "reach", "pops", "svhc"]


# -------------------------- å·¥å…·å‡½æ•° --------------------------
def filter_invalid_filename_chars(filename):
    """è¿‡æ»¤æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦"""
    invalid_chars = ['\\', '/', ':', '*', '?', '"', '<', '>', '|']
    for char in invalid_chars:
        filename = filename.replace(char, '_')
    return filename.strip()


def clean_field_content(content):
    """æ¸…æ´—æå–çš„ä¸­æ–‡å­—æ®µå†…å®¹"""
    if content == "æœªæ‰¾åˆ°å¯¹åº”å†…å®¹":
        return content
    # å»æ‰ä¸­è‹±æ–‡å†’å·ã€å¤šä½™ç©ºæ ¼ï¼Œç»Ÿä¸€æ ¼å¼
    content = content.replace("ï¼š", "").replace(":", "") \
        .replace("ï¼Œ", ",").strip()
    # åˆå¹¶å¤šä¸ªè¿ç»­ç©ºæ ¼ä¸ºä¸€ä¸ª
    content = re.sub(r'\s+', ' ', content)
    return content


def calculate_expire_date(receive_date_str, days=365):
    """è®¡ç®—è¿‡æœŸæ—¶é—´ï¼ˆä»…è§£æä¸­æ–‡æ—¥æœŸï¼Œå¦‚2025.05.08/2025å¹´05æœˆ08æ—¥ï¼‰"""
    try:
        # å…¼å®¹ä¸­æ–‡æ—¥æœŸæ ¼å¼è§£æ
        receive_date = parse(receive_date_str, fuzzy=True)
        expire_date = receive_date + timedelta(days=days)
        # ç»Ÿä¸€è¾“å‡ºä¸ºâ€œXXXXå¹´XXæœˆXXæ—¥â€æ ¼å¼
        return expire_date.strftime("%Yå¹´%mæœˆ%dæ—¥")
    except Exception as e:
        print(f"âš ï¸ æ—¥æœŸè§£æå¤±è´¥ï¼š{receive_date_str}ï¼Œé”™è¯¯ï¼š{e}")
        return "æ—¥æœŸè§£æå¤±è´¥"


def get_unique_filename(file_dir, base_filename):
    """ç”Ÿæˆä¸é‡å¤çš„æ–‡ä»¶åï¼ˆä»…å½“æ–‡ä»¶é‡åæ—¶æ·»åŠ ç¼–å·ï¼‰"""
    filename_no_ext, ext = os.path.splitext(base_filename)
    unique_path = os.path.join(file_dir, base_filename)
    duplicate_num = 1
    # ä»…æ–‡ä»¶å­˜åœ¨æ—¶æ·»åŠ é‡åç¼–å·
    while os.path.exists(unique_path):
        new_filename = f"{filename_no_ext}_é‡å{duplicate_num}{ext}"
        unique_path = os.path.join(file_dir, new_filename)
        duplicate_num += 1
    return unique_path


# -------------------------- æ ¸å¿ƒæå–å‡½æ•°ï¼ˆä»…æå–ä¸­æ–‡å­—æ®µï¼‰ --------------------------
def pdfplumber_extract_multi_page(pdf_path, target_keys, target_keywords):
    extract_result = {key: "æœªæ‰¾åˆ°å¯¹åº”å†…å®¹" for key in target_keys}
    extract_result["æ£€æµ‹ç±»å‹"] = ""
    matched_keywords = set()
    full_text = ""

    try:
        with pdfplumber.open(pdf_path) as pdf:
            # éå†æ‰€æœ‰é¡µé¢æå–åŸç”Ÿæ–‡æœ¬
            for page_num, page in enumerate(pdf.pages, start=1):
                page_text = page.extract_text()
                if page_text:
                    full_text += f"\nã€ç¬¬{page_num}é¡µã€‘\n{page_text}"
                # è°ƒè¯•ï¼šæ‰“å°ç¬¬1é¡µåŸå§‹æ–‡æœ¬ï¼ˆæ–¹ä¾¿æ’æŸ¥æå–é—®é¢˜ï¼‰
                if page_num == 1:
                    print(f"\nã€è°ƒè¯•ã€‘{pdf_path} ç¬¬{page_num}é¡µåŸå§‹æ–‡æœ¬ï¼š\n{page_text}\n")

        # æ— åŸç”Ÿæ–‡æœ¬ï¼ˆæ‰«æç‰ˆï¼‰ç›´æ¥è¿”å›
        if not full_text.strip():
            print(f"âš ï¸ è¯¥PDFæ— åŸç”Ÿæ–‡æœ¬ï¼ˆå¯èƒ½æ˜¯æ‰«æç‰ˆï¼‰ï¼Œæ— æ³•æå–å­—æ®µ")
            return extract_result

        # ä»…åŒ¹é…ä¸­æ–‡æ ‡æ³¨çš„å­—æ®µ
        for key, patterns in target_keys.items():
            if extract_result[key] == "æœªæ‰¾åˆ°å¯¹åº”å†…å®¹":
                for pattern in patterns:
                    # ä»…åŒ¹é…ä¸­æ–‡ï¼Œå…³é—­å¿½ç•¥å¤§å°å†™ï¼ˆä¸­æ–‡æ— å¤§å°å†™ï¼‰
                    match = re.search(pattern, full_text, re.MULTILINE | re.DOTALL)
                    if match:
                        extract_result[key] = match.group(1).strip()
                        break

        # æå–æ£€æµ‹ç±»å‹ï¼ˆå…¼å®¹ä¸­è‹±æ–‡å…³é”®è¯ï¼Œä½†ä»…ä½œä¸ºå¯é€‰å­—æ®µï¼‰
        full_text_lower = full_text.lower()
        for keyword in target_keywords:
            if keyword in full_text_lower:
                matched_keywords.add(keyword.upper())
        extract_result["æ£€æµ‹ç±»å‹"] = "/".join(matched_keywords) if matched_keywords else ""
        # æ ‡è®°æå–çŠ¶æ€
        extract_result["æ‰¾åˆ°å†…å®¹çš„é¡µç "] = "åŸç”Ÿæ–‡æœ¬æå–" if any(v != "æœªæ‰¾åˆ°å¯¹åº”å†…å®¹" for v in extract_result.values()) else "æ‰€æœ‰é¡µå‡æœªæ‰¾åˆ°"

    except Exception as e:
        extract_result = {"error": f"æå–å¤±è´¥ï¼š{str(e)}"}

    return extract_result


# -------------------------- å•æ–‡ä»¶é‡å‘½åå‡½æ•° --------------------------
def rename_single_pdf(original_path):
    print(f"\n========== å¼€å§‹å¤„ç†æ–‡ä»¶ï¼š{original_path} ==========")

    # 1. æå–PDFå†…å®¹ï¼ˆä»…ä¸­æ–‡å­—æ®µï¼‰
    extract_result = pdfplumber_extract_multi_page(original_path, target_keys, target_keywords)

    # æ‰“å°æå–ç»“æœï¼ˆæ¸…æ´—å‰ï¼‰
    print("æå–ç»“æœï¼ˆæ¸…æ´—å‰ï¼‰ï¼š")
    for key, value in extract_result.items():
        print(f"  {key}ï¼š{value}")

    # 2. æ£€æŸ¥æå–é”™è¯¯
    if "error" in extract_result:
        print(f"âŒ æå–å¤±è´¥ï¼Œè·³è¿‡é‡å‘½åï¼š{extract_result['error']}")
        return False

    # 3. æ¸…æ´—å­—æ®µï¼ˆä»…ä¿ç•™ä¸­æ–‡å†…å®¹ï¼‰
    customer_name = clean_field_content(extract_result["å®¢æˆ·åç§°"])
    sample_name = clean_field_content(extract_result["æ ·å“åç§°"])
    receive_date = clean_field_content(extract_result["æ ·å“æ¥æ”¶æ—¶é—´"])
    detect_type = extract_result["æ£€æµ‹ç±»å‹"]

    # æ‰“å°æ¸…æ´—åçš„ç»“æœ
    print("æå–ç»“æœï¼ˆæ¸…æ´—åï¼‰ï¼š")
    print(f"  å®¢æˆ·åç§°ï¼š{customer_name}")
    print(f"  æ ·å“åç§°ï¼š{sample_name}")
    print(f"  æ ·å“æ¥æ”¶æ—¶é—´ï¼š{receive_date}")
    print(f"  æ£€æµ‹ç±»å‹ï¼š{detect_type}")

    # 4. æ£€æŸ¥å¿…å¡«ä¸­æ–‡å­—æ®µï¼ˆç¼ºä¸€ä¸å¯ï¼‰
    required_fields = [customer_name, sample_name, receive_date]
    if any(v == "æœªæ‰¾åˆ°å¯¹åº”å†…å®¹" for v in required_fields):
        print(f"âŒ å…³é”®å¿…å¡«ä¸­æ–‡å­—æ®µç¼ºå¤±ï¼Œè·³è¿‡é‡å‘½å")
        return False

    # 5. è®¡ç®—è¿‡æœŸæ—¶é—´
    expire_date = calculate_expire_date(receive_date, expire_days)
    if expire_date == "æ—¥æœŸè§£æå¤±è´¥":
        print(f"âŒ è¿‡æœŸæ—¶é—´è®¡ç®—å¤±è´¥ï¼Œè·³è¿‡é‡å‘½å")
        return False

    # 6. æ‹¼æ¥æ–‡ä»¶åï¼ˆä»…ä¸­æ–‡æ ¸å¿ƒå­—æ®µï¼‰
    filename_parts = [
        customer_name,  # æŠ¥å‘ŠæŠ¬å¤´å…¬å¸åç§°ï¼ˆä¸­æ–‡ï¼‰
        sample_name,    # æ ·å“åç§°ï¼ˆä¸­æ–‡ï¼‰
        receive_date,   # æ ·å“æ¥æ”¶æ—¥æœŸï¼ˆä¸­æ–‡ï¼‰
        f"è¿‡æœŸæ—¶é—´({expire_date})"  # è¿‡æœŸæ—¶é—´ï¼ˆä¸­æ–‡æ ¼å¼ï¼‰
    ]
    # æ£€æµ‹ç±»å‹æœ‰å€¼æ—¶è¿½åŠ ï¼ˆå¯é€‰ï¼‰
    if detect_type and detect_type.strip():
        filename_parts.append(detect_type)
    # è¿‡æ»¤ç©ºå€¼ï¼Œé¿å…æ–‡ä»¶åæ··ä¹±
    filename_parts = [part for part in filename_parts if part and part != "æœªæ‰¾åˆ°å¯¹åº”å†…å®¹"]
    base_filename = "_".join(filename_parts) + ".pdf"
    # è¿‡æ»¤éæ³•å­—ç¬¦
    base_filename = filter_invalid_filename_chars(base_filename)

    # 7. ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
    original_dir = os.path.dirname(original_path)
    new_pdf_path = get_unique_filename(original_dir, base_filename)

    # 8. æ‰§è¡Œé‡å‘½å
    try:
        os.rename(original_path, new_pdf_path)
        print(f"âœ… é‡å‘½åæˆåŠŸï¼æ–°è·¯å¾„ï¼š{new_pdf_path}")
        return True
    except Exception as e:
        print(f"âŒ é‡å‘½åå¤±è´¥ï¼š{str(e)}")
        return False


# -------------------------- æ‰¹é‡å¤„ç†å‡½æ•° --------------------------
def batch_process_pdfs(target_dir):
    total_count = 0
    success_count = 0
    fail_count = 0
    fail_files = []

    # éå†ç›®æ ‡æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰PDF
    for root, dirs, files in os.walk(target_dir):
        for file in files:
            if file.lower().endswith(".pdf"):
                total_count += 1
                file_path = os.path.join(root, file)
                # å¤„ç†å•ä¸ªPDF
                if rename_single_pdf(file_path):
                    success_count += 1
                else:
                    fail_count += 1
                    fail_files.append(file_path)

    # æ‰“å°æ‰¹é‡å¤„ç†æ±‡æ€»
    print("\n========== æ‰¹é‡å¤„ç†å®Œæˆ ==========")
    print(f"ğŸ“Š æ±‡æ€»ç»Ÿè®¡ï¼š")
    print(f"  æ€»å¤„ç†PDFæ•°é‡ï¼š{total_count}")
    print(f"  âœ… æˆåŠŸé‡å‘½åï¼š{success_count}")
    print(f"  âŒ é‡å‘½åå¤±è´¥ï¼š{fail_count}")

    # æ‰“å°å¤±è´¥æ–‡ä»¶åˆ—è¡¨
    if fail_files:
        print(f"\nâŒ å¤±è´¥çš„æ–‡ä»¶åˆ—è¡¨ï¼š")
        for fail_file in fail_files:
            print(f"  - {fail_file}")


# -------------------------- ä¸»æ‰§è¡Œé€»è¾‘ --------------------------
if __name__ == "__main__":
    # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
    if not os.path.exists(TARGET_DIR):
        print(f"âŒ ç›®æ ‡ç›®å½•ä¸å­˜åœ¨ï¼š{TARGET_DIR}")
    else:
        # å¯åŠ¨æ‰¹é‡å¤„ç†
        batch_process_pdfs(TARGET_DIR)