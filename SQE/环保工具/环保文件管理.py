import pdfplumber
import re
import os
from datetime import datetime, timedelta
from dateutil.parser import parse  # å…¼å®¹å¤šè¯­è¨€/å¤šæ ¼å¼æ—¥æœŸè§£æ

# -------------------------- å…¨å±€é…ç½®é¡¹ --------------------------
TARGET_DIR = r'E:\System\download\å‚å•†ROHSã€REACH - å‰¯æœ¬\4-ä¸€è¯º'
# ä¼˜åŒ–åçš„å­—æ®µåŒ¹é…è§„åˆ™ï¼ˆæè‡´å…¼å®¹è‹±æ–‡æ¨¡æ¿æ’ç‰ˆï¼‰
target_keys = {
    "å®¢æˆ·åç§°": [
        # å…¼å®¹ä»»æ„æ‹†è¡Œ/ç©ºæ ¼ï¼šåŒ¹é…"Company Name" + ä»»æ„å­—ç¬¦ + "shown on Report" åçš„å€¼
        r"Company Name.*shown on Report[\s:]*\n?[\s:]*([^\n]+)",
        # å…œåº•åŒ¹é…ï¼šåªè¦åŒ…å«"Company Name"ï¼Œå°±å–åç»­ç¬¬ä¸€è¡Œæœ‰æ•ˆå†…å®¹
        r"Company Name[\s\S]*?\n\s*([^\n]+)",
        # åŸæœ‰ä¸­æ–‡å…¼å®¹è§„åˆ™
        r"å®¢æˆ·åç§°\s*[:ï¼š]\s*([^\n]+)",
        r"æŠ¥å‘ŠæŠ¬å¤´å…¬å¸åç§°\s*([^\n]+)",
        r"Client Name\s*[:]?\s*([^\n]+)",
    ],
    "æ ·å“åç§°": [
        # å…¼å®¹æ‹†è¡Œ/ç©ºæ ¼ï¼šåŒ¹é…"Sample Name"åçš„å€¼ï¼ˆä¸ç®¡æ˜¯å¦æ¢è¡Œï¼‰
        r"Sample Name[\s:]*\n?[\s:]*([^\n]+)",
        # å…œåº•ï¼šSample Name + ä»»æ„å­—ç¬¦åå–ç¬¬ä¸€è¡Œå†…å®¹
        r"Sample Name[\s\S]*?\n\s*([^\n]+)",
        # åŸæœ‰ä¸­æ–‡å…¼å®¹è§„åˆ™
        r"æ ·å“åç§°\s*[:ï¼š]\s*([^\n]+)",
    ],
    "æ ·å“æ¥æ”¶æ—¶é—´": [
        # å…¼å®¹æ‹†è¡Œ/ç©ºæ ¼ï¼šåŒ¹é…"Sample Received Date"åçš„å€¼
        r"Sample Received Date[\s:]*\n?[\s:]*([^\n]+)",
        # å…œåº•ï¼šSample Received Date + ä»»æ„å­—ç¬¦åå–ç¬¬ä¸€è¡Œå†…å®¹
        r"Sample Received Date[\s\S]*?\n\s*([^\n]+)",
        # åŸæœ‰ä¸­æ–‡å…¼å®¹è§„åˆ™
        r"æ”¶æ ·æ—¥æœŸ\s*[:ï¼š]\s*([^\n]+)",
        r"æ ·å“æ¥æ”¶æ—¥æœŸ\s*([^\n]+)",
        r"æ ·å“æ¥æ”¶æ—¶é—´\s*([^\n]+)",
        r"Sample Receiving Date\s*[:]?\s*([^\n]+)",
    ]
}
expire_days = 365
# æ£€æµ‹å…³é”®è¯ï¼šä»»æ„åŒ¹é…ã€æ— é¡ºåºã€éå†å…¨é¡µ
target_keywords = ["rohs", "reach", "pops", "svhc"]


# -------------------------- å·¥å…·å‡½æ•° --------------------------
def filter_invalid_filename_chars(filename):
    invalid_chars = ['\\', '/', ':', '*', '?', '"', '<', '>', '|']
    for char in invalid_chars:
        filename = filename.replace(char, '_')
    return filename.strip()


def clean_field_content(content):
    """æ¸…æ´—æå–çš„å­—æ®µå†…å®¹ï¼šå»æ‰ä¸­è‹±æ–‡å†’å·ã€å‰åç©ºç™½ã€å¤šä½™ç©ºæ ¼ï¼Œæ›¿æ¢ä¸­æ–‡é€—å·ä¸ºè‹±æ–‡é€—å·"""
    if content == "æœªæ‰¾åˆ°å¯¹åº”å†…å®¹":
        return content
    # å»æ‰ä¸­è‹±æ–‡å†’å·ã€å¤šä½™ç©ºæ ¼ï¼Œæ›¿æ¢ä¸­æ–‡é€—å·ä¸ºè‹±æ–‡é€—å·ï¼ˆé¿å…æ–‡ä»¶åä¹±ç ï¼‰
    content = content.replace("ï¼š", "").replace(":", "") \
        .replace("ï¼Œ", ",").strip()
    # åˆå¹¶å¤šä¸ªè¿ç»­ç©ºæ ¼ä¸ºä¸€ä¸ª
    content = re.sub(r'\s+', ' ', content)
    return content


def calculate_expire_date(receive_date_str, days=365):
    try:
        # å…¼å®¹è‹±æ–‡æ—¥æœŸï¼ˆJan. 2, 2025ï¼‰å’Œä¸­æ–‡æ—¥æœŸï¼ˆ2024å¹´06æœˆ26æ—¥ï¼‰è§£æ
        receive_date = parse(receive_date_str, fuzzy=True)
        expire_date = receive_date + timedelta(days=days)
        # ç»Ÿä¸€è¿‡æœŸæ—¶é—´è¾“å‡ºæ ¼å¼ä¸ºâ€œXXXXå¹´XXæœˆXXæ—¥â€ï¼Œä¿è¯æ–‡ä»¶åæ ¼å¼ä¸€è‡´
        return expire_date.strftime("%Yå¹´%mæœˆ%dæ—¥")
    except Exception as e:
        print(f"âš ï¸ æ—¥æœŸè§£æå¤±è´¥ï¼š{receive_date_str}ï¼Œé”™è¯¯ï¼š{e}")
        return "æ—¥æœŸè§£æå¤±è´¥"


def get_unique_filename(file_dir, base_filename):
    filename_no_ext, ext = os.path.splitext(base_filename)
    unique_path = os.path.join(file_dir, base_filename)
    duplicate_num = 1
    while os.path.exists(unique_path):
        new_filename = f"{filename_no_ext}_é‡å{duplicate_num}{ext}"
        unique_path = os.path.join(file_dir, new_filename)
        duplicate_num += 1
    return unique_path


# -------------------------- æ ¸å¿ƒæå–å‡½æ•°ï¼ˆä»…ä¿ç•™pdfplumberï¼‰ --------------------------
def pdfplumber_extract_multi_page(pdf_path, target_keys, target_keywords):
    extract_result = {key: "æœªæ‰¾åˆ°å¯¹åº”å†…å®¹" for key in target_keys}
    extract_result["æ£€æµ‹ç±»å‹"] = ""
    # æ”¶é›†æ‰€æœ‰åŒ¹é…çš„æ£€æµ‹å…³é”®è¯ï¼ˆå»é‡ï¼‰
    matched_keywords = set()
    full_text = ""

    try:
        with pdfplumber.open(pdf_path) as pdf:
            # å¼ºåˆ¶éå†PDFæ‰€æœ‰é¡µé¢ï¼Œæå–åŸç”Ÿæ–‡æœ¬
            for page_num, page in enumerate(pdf.pages, start=1):
                page_text = page.extract_text()
                if page_text:
                    full_text += f"\nã€ç¬¬{page_num}é¡µã€‘\n{page_text}"
                # ========== è°ƒè¯•ï¼šæ‰“å°ç¬¬1é¡µåŸå§‹æ–‡æœ¬ ==========
                if page_num == 1:
                    print(f"\nã€è°ƒè¯•ã€‘{pdf_path} ç¬¬{page_num}é¡µåŸå§‹æ–‡æœ¬ï¼š\n{page_text}\n")

        # è‹¥åŸç”Ÿæ–‡æœ¬ä¸ºç©ºï¼Œç›´æ¥è¿”å›æœªæ‰¾åˆ°
        if not full_text.strip():
            print(f"âš ï¸ è¯¥PDFæ— åŸç”Ÿæ–‡æœ¬ï¼ˆå¯èƒ½æ˜¯æ‰«æç‰ˆï¼‰ï¼Œæ— æ³•æå–å­—æ®µ")
            return extract_result

        # 1. æå–åŸºç¡€ä¿¡æ¯ï¼ˆå®¢æˆ·/æ ·å“/æ—¶é—´ï¼‰ï¼šåŒ¹é…åˆ°åä¸å†é‡å¤æå–
        for key, patterns in target_keys.items():
            if extract_result[key] == "æœªæ‰¾åˆ°å¯¹åº”å†…å®¹":
                for pattern in patterns:
                    match = re.search(pattern, full_text, re.IGNORECASE | re.MULTILINE | re.DOTALL)
                    if match:
                        extract_result[key] = match.group(1).strip()
                        break

        # 2. æå–æ£€æµ‹ç±»å‹ï¼šéå†å…¨é¡µ+æ”¶é›†æ‰€æœ‰åŒ¹é…çš„å…³é”®è¯ï¼ˆæ— é¡ºåºã€å»é‡ï¼‰
        full_text_lower = full_text.lower()
        for keyword in target_keywords:
            if keyword in full_text_lower:
                matched_keywords.add(keyword.upper())  # è½¬å¤§å†™å¹¶å­˜å…¥é›†åˆï¼ˆè‡ªåŠ¨å»é‡ï¼‰

        # å¤„ç†æ£€æµ‹ç±»å‹ï¼šå°†é›†åˆè½¬ä¸ºæ–œæ åˆ†éš”çš„å­—ç¬¦ä¸²ï¼ˆæ— é¡ºåºï¼‰
        if matched_keywords:
            extract_result["æ£€æµ‹ç±»å‹"] = "/".join(matched_keywords)
        else:
            extract_result["æ£€æµ‹ç±»å‹"] = ""

        # è®°å½•æ‰¾åˆ°åŸºç¡€ä¿¡æ¯çš„é¡µç ï¼ˆä»…ç”¨äºæ—¥å¿—ï¼‰
        extract_result["æ‰¾åˆ°å†…å®¹çš„é¡µç "] = "åŸç”Ÿæ–‡æœ¬æå–" if any(v != "æœªæ‰¾åˆ°å¯¹åº”å†…å®¹" for v in extract_result.values()) else "æ‰€æœ‰é¡µå‡æœªæ‰¾åˆ°"

    except Exception as e:
        extract_result = {"error": f"æå–å¤±è´¥ï¼š{str(e)}"}

    return extract_result


# -------------------------- å•æ–‡ä»¶é‡å‘½åå‡½æ•° --------------------------
def rename_single_pdf(original_path):
    print(f"\n========== å¼€å§‹å¤„ç†æ–‡ä»¶ï¼š{original_path} ==========")

    # 1. æå–PDFå†…å®¹ï¼ˆä»…åŸç”Ÿæ–‡æœ¬ï¼‰
    extract_result = pdfplumber_extract_multi_page(original_path, target_keys, target_keywords)

    # æ‰“å°æå–ç»“æœï¼ˆæ¸…æ´—å‰ï¼‰
    print("æå–ç»“æœï¼ˆæ¸…æ´—å‰ï¼‰ï¼š")
    for key, value in extract_result.items():
        print(f"  {key}ï¼š{value}")

    # 2. æ£€æŸ¥æå–ç»“æœæ˜¯å¦æœ‰é”™è¯¯
    if "error" in extract_result:
        print(f"âŒ æå–å¤±è´¥ï¼Œè·³è¿‡é‡å‘½åï¼š{extract_result['error']}")
        return False

    # 3. æå–æ ¸å¿ƒä¿¡æ¯ + æ¸…æ´—å­—æ®µ
    customer_name = clean_field_content(extract_result["å®¢æˆ·åç§°"])
    sample_name = clean_field_content(extract_result["æ ·å“åç§°"])
    receive_date = clean_field_content(extract_result["æ ·å“æ¥æ”¶æ—¶é—´"])
    detect_type = extract_result["æ£€æµ‹ç±»å‹"]

    # æ‰“å°æ¸…æ´—åçš„ç»“æœ
    print("æå–ç»“æœï¼ˆæ¸…æ´—åï¼‰ï¼š")
    print(f"  å®¢æˆ·åç§°ï¼š{customer_name}")
    print(f"  æ ·å“åç§°ï¼š{sample_name}")
    print(f"  æ ·å“æ¥æ”¶æ—¶é—´ï¼š{receive_date}")
    print(f"  æ£€æµ‹ç±»å‹ï¼š{detect_type}")

    # 4. æ£€æŸ¥æ ¸å¿ƒä¿¡æ¯ç¼ºå¤±ï¼ˆå®¢æˆ·åç§°/æ ·å“åç§°/æ ·å“æ¥æ”¶æ—¶é—´ä¸ºå¿…å¡«ï¼‰
    required_fields = [customer_name, sample_name, receive_date]
    if any(v == "æœªæ‰¾åˆ°å¯¹åº”å†…å®¹" for v in required_fields):
        print(f"âŒ å…³é”®å¿…å¡«ä¿¡æ¯ç¼ºå¤±ï¼ˆå®¢æˆ·åç§°/æ ·å“åç§°/æ ·å“æ¥æ”¶æ—¶é—´ï¼‰ï¼Œè·³è¿‡é‡å‘½å")
        return False

    # 5. è®¡ç®—è¿‡æœŸæ—¶é—´ï¼ˆå…¼å®¹è‹±æ–‡æ—¥æœŸè§£æï¼‰
    expire_date = calculate_expire_date(receive_date, expire_days)
    if expire_date == "æ—¥æœŸè§£æå¤±è´¥":
        print(f"âŒ è¿‡æœŸæ—¶é—´è®¡ç®—å¤±è´¥ï¼Œè·³è¿‡é‡å‘½å")
        return False

    # 6. æ‹¼æ¥åŸºç¡€æ–°æ–‡ä»¶å
    filename_parts = [
        customer_name,
        sample_name,
        receive_date,
        f"è¿‡æœŸæ—¶é—´({expire_date})"
    ]
    # æ£€æµ‹ç±»å‹æœ‰å€¼æ‰æ‹¼æ¥
    if detect_type:
        filename_parts.append(detect_type)

    # æ‹¼æ¥æ‰€æœ‰éƒ¨åˆ†ï¼Œä¸‹åˆ’çº¿åˆ†éš”
    base_filename = "_".join(filename_parts) + ".pdf"
    # è¿‡æ»¤éæ³•å­—ç¬¦
    base_filename = filter_invalid_filename_chars(base_filename)

    # 7. è·å–æ–‡ä»¶æ‰€åœ¨ç›®å½•
    original_dir = os.path.dirname(original_path)

    # 8. ç”Ÿæˆä¸é‡å¤æ–‡ä»¶å
    new_pdf_path = get_unique_filename(original_dir, base_filename)

    # 9. æ‰§è¡Œé‡å‘½å
    try:
        os.rename(original_path, new_pdf_path)
        print(f"âœ… é‡å‘½åæˆåŠŸï¼æ–°è·¯å¾„ï¼š{new_pdf_path}")
        return True
    except Exception as e:
        print(f"âŒ é‡å‘½åå¤±è´¥ï¼š{str(e)}")
        return False


# -------------------------- æ‰¹é‡å¤„ç†å‡½æ•° --------------------------
def batch_process_pdfs(target_dir):
    total_count = 0
    success_count = 0
    fail_count = 0
    fail_files = []

    for root, dirs, files in os.walk(target_dir):
        for file in files:
            if file.lower().endswith(".pdf"):
                total_count += 1
                file_path = os.path.join(root, file)
                if rename_single_pdf(file_path):
                    success_count += 1
                else:
                    fail_count += 1
                    fail_files.append(file_path)

    print("\n========== æ‰¹é‡å¤„ç†å®Œæˆ ==========")
    print(f"ğŸ“Š æ±‡æ€»ç»Ÿè®¡ï¼š")
    print(f"  æ€»å¤„ç†PDFæ•°é‡ï¼š{total_count}")
    print(f"  âœ… æˆåŠŸé‡å‘½åï¼š{success_count}")
    print(f"  âŒ é‡å‘½åå¤±è´¥ï¼š{fail_count}")

    if fail_files:
        print(f"\nâŒ å¤±è´¥çš„æ–‡ä»¶åˆ—è¡¨ï¼š")
        for fail_file in fail_files:
            print(f"  - {fail_file}")


# -------------------------- ä¸»æ‰§è¡Œé€»è¾‘ --------------------------
if __name__ == "__main__":
    if not os.path.exists(TARGET_DIR):
        print(f"âŒ ç›®æ ‡ç›®å½•ä¸å­˜åœ¨ï¼š{TARGET_DIR}")
    else:
        batch_process_pdfs(TARGET_DIR)